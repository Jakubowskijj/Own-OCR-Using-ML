{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "with open(\"labelj.json\",\"r\") as file:\n",
    "    data=json.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'annotations': [{'id': 1,\n",
       "   'completed_by': 1,\n",
       "   'result': [{'original_width': 1536,\n",
       "     'original_height': 2048,\n",
       "     'image_rotation': 0,\n",
       "     'value': {'points': [[14.192487384209254, 8.59448138433522],\n",
       "       [88.99872297181221, 9.037996615091759],\n",
       "       [92.30438982505096, 94.3938499517012],\n",
       "       [8.228685914636326, 92.91805302135883]],\n",
       "      'closed': True,\n",
       "      'polygonlabels': ['kartka']},\n",
       "     'id': 'uWscj3vOH4',\n",
       "     'from_name': 'label',\n",
       "     'to_name': 'image',\n",
       "     'type': 'polygonlabels',\n",
       "     'origin': 'manual'}],\n",
       "   'was_cancelled': False,\n",
       "   'ground_truth': False,\n",
       "   'created_at': '2023-05-10T23:11:05.421553Z',\n",
       "   'updated_at': '2023-05-10T23:11:05.421589Z',\n",
       "   'lead_time': 106.427,\n",
       "   'prediction': {},\n",
       "   'result_count': 0,\n",
       "   'unique_id': '287b96a9-d6e7-4da0-bc48-b6b5f7808900',\n",
       "   'last_action': None,\n",
       "   'task': 1,\n",
       "   'project': 1,\n",
       "   'updated_by': 1,\n",
       "   'parent_prediction': None,\n",
       "   'parent_annotation': None,\n",
       "   'last_created_by': None}],\n",
       " 'file_upload': '764437c2-proba1.jpg',\n",
       " 'drafts': [],\n",
       " 'predictions': [],\n",
       " 'data': {'image': '/data/upload/1/764437c2-proba1.jpg'},\n",
       " 'meta': {},\n",
       " 'created_at': '2023-05-10T23:09:11.181308Z',\n",
       " 'updated_at': '2023-05-10T23:11:05.744951Z',\n",
       " 'inner_id': 1,\n",
       " 'total_annotations': 1,\n",
       " 'cancelled_annotations': 0,\n",
       " 'total_predictions': 0,\n",
       " 'comment_count': 0,\n",
       " 'unresolved_comment_count': 0,\n",
       " 'last_comment_updated_at': None,\n",
       " 'project': 1,\n",
       " 'updated_by': 1,\n",
       " 'comment_authors': []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument lambd should be callable, got 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m     draw\u001b[39m.\u001b[39mellipse((point[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m radius, point[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m radius, point[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m radius, point[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m radius), fill\u001b[39m=\u001b[39mcolor)\n\u001b[0;32m     22\u001b[0m \u001b[39m# Wyświetlanie zdjęcia\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m#image.show()\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m elastic_transformer \u001b[39m=\u001b[39m  T\u001b[39m.\u001b[39;49mLambda(\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     25\u001b[0m transformed_imgs \u001b[39m=\u001b[39m [elastic_transformer(orig_img) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m)]\n\u001b[0;32m     26\u001b[0m transformed_imgs[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:482\u001b[0m, in \u001b[0;36mLambda.__init__\u001b[1;34m(self, lambd)\u001b[0m\n\u001b[0;32m    480\u001b[0m _log_api_usage_once(\u001b[39mself\u001b[39m)\n\u001b[0;32m    481\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(lambd):\n\u001b[1;32m--> 482\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mArgument lambd should be callable, got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mtype\u001b[39m(lambd)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    483\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlambd \u001b[39m=\u001b[39m lambd\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument lambd should be callable, got 'int'"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "orig_img=Image.open(\"proba1.jpg\")\n",
    "\n",
    "# Otwieranie zdjęcia\n",
    "image = Image.open(\"proba1.jpg\")\n",
    "\n",
    "# Tworzenie obiektu ImageDraw\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Definiowanie współrzędnych i rysowanie kropek\n",
    "points = [ (218, 176) ,(1367, 185), (1418, 1933), (126, 1903)]\n",
    "radius = 5  # Rozmiar kropki\n",
    "color = (255, 0, 0)  # Kolor czerwony (RGB)\n",
    "\n",
    "for point in points:\n",
    "    draw.ellipse((point[0] - radius, point[1] - radius, point[0] + radius, point[1] + radius), fill=color)\n",
    "\n",
    "# Wyświetlanie zdjęcia\n",
    "#image.show()\n",
    "elastic_transformer =  T.Lambda(1)\n",
    "transformed_imgs = [elastic_transformer(orig_img) for _ in range(2)]\n",
    "transformed_imgs[1].show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "orig_imgs = [\n",
    "    Image.open('proba1.jpg'),\n",
    "    Image.open('proba2.jpg'),\n",
    "    Image.open('proba3.jpg'),\n",
    "    Image.open('proba4.jpg'),\n",
    "    Image.open('proba5.jpg'),\n",
    "    Image.open('proba6.jpg'),\n",
    "    Image.open('proba7.jpg'),\n",
    "    Image.open('proba8.jpg'),\n",
    "    Image.open('proba9.jpg'),\n",
    "    Image.open('proba10.jpg'),\n",
    "    Image.open('proba11.jpg'),\n",
    "    Image.open('proba12.jpg'),\n",
    "    Image.open('proba13.jpg'),\n",
    "    Image.open('proba14.jpg'),\n",
    "    # Dodaj więcej obrazów, jeśli jest to potrzebne\n",
    "]\n",
    "# if you change the seed, make sure that the randomly-applied transforms\n",
    "# properly show that the image can be both transformed and *not* transformed!\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "def plot(imgs, with_orig=True, row_title=None, **imshow_kwargs):\n",
    "    if not isinstance(imgs[0], list):\n",
    "        # Make a 2d grid even if there's just 1 row\n",
    "        imgs = [imgs]\n",
    "\n",
    "    num_rows = len(imgs)\n",
    "    num_cols = len(imgs[0]) + with_orig\n",
    "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False)\n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        row = [orig_imgs[idx]] + row if with_orig else row\n",
    "        for col_idx, img in enumerate(row):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
    "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    if with_orig:\n",
    "        axs[0, 0].set(title='Original image')\n",
    "        axs[0, 0].title.set_size(8)\n",
    "    if row_title is not None:\n",
    "        for row_idx in range(num_rows):\n",
    "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,2):\n",
    "    rotater = T.RandomRotation(degrees=(0, 180))\n",
    "    rotated_imgs = [rotater(orig_imgs[i]) for _ in range(41)]\n",
    "    rotated_imgs[2].show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
