{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import json\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T21:34:44.530435300Z",
     "start_time": "2023-06-07T21:34:44.520426200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TrainingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, validation=False):\n",
    "        self.images = []\n",
    "        self.boxes = []\n",
    "\n",
    "\n",
    "        x_final, y_final = 600, 1200\n",
    "        transform = Resize((x_final, y_final))\n",
    "        to_tensor = ToTensor()\n",
    "        for item in data:\n",
    "            file_name = item['data']['image'].split('-')[-1]\n",
    "\n",
    "            image_path = file_name  # Zmień odpowiednio ścieżkę do katalogu ze zdjęciami\n",
    "            image = Image.open(image_path)\n",
    "            image = to_tensor(transform(image))*255\n",
    "            image = image.type(torch.uint8)\n",
    "            self.images.append(image)\n",
    "            points = item['annotations'][0]['result'][0]['value']['points']\n",
    "\n",
    "            xmin = min(point[0] for point in points)/100*x_final\n",
    "            ymin = min(point[1] for point in points)/100*y_final\n",
    "            xmax = max(point[0] for point in points)/100*x_final\n",
    "            ymax = max(point[1] for point in points)/100*y_final\n",
    "            box = torch.tensor([[xmin, ymin, xmax, ymax]])\n",
    "            self.boxes.append(box)\n",
    "\n",
    "        self.labels = torch.zeros((len(data), 1), dtype=torch.int64)\n",
    "\n",
    "\n",
    "        transforms = [#T.ElasticTransform(alpha=5.0), #T.Grayscale(),\n",
    "                    #   T.ColorJitter(brightness=.5, hue=.3),\n",
    "                    #   T.RandomInvert(p=0.3), T.RandomPosterize(bits=2),\n",
    "                    #   T.RandomSolarize(threshold=0.2),\n",
    "                    #   T.RandomAdjustSharpness(sharpness_factor=1),\n",
    "                    #   T.RandomAutocontrast(),\n",
    "                    #   T.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "                       T.RandomGrayscale(p=0.5),\n",
    "                    #   T.RandomSolarize(1, p=0.5)\n",
    "\n",
    "\n",
    "\n",
    "                      ]\n",
    "        # self.transforms = T.Compose([*[T.RandomApply([transform], p=0.5) for transform in transforms]])\n",
    "        # if validation:\n",
    "        #     self.transforms = None\n",
    "        transforms = transforms * 5\n",
    "\n",
    "        self.transforms = T.Compose([T.RandomApply(transforms, p=0.5)])\n",
    "\n",
    "    # def crop_img_with_box(self, img, box):\n",
    "    #     # TODO: crop image with box\n",
    "    #     return img, box\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_img = self.images[idx]\n",
    "        if self.transforms is not None:\n",
    "            out_img = self.transforms(out_img)\n",
    "\n",
    "        out_box = self.boxes[idx]\n",
    "        # out_img, out_box = self.crop_img_with_box(out_img, out_box)\n",
    "        return out_img/255, out_box, self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T21:34:49.747175900Z",
     "start_time": "2023-06-07T21:34:49.217695200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn()\n",
    "model.roi_heads.box_predictor.cls_score = nn.Linear(1024, 1, bias=True)\n",
    "model.roi_heads.box_predictor.bbox_pred = nn.Linear(1024, 4, bias=True)\n",
    "\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights\n",
    "\n",
    "#Opcjonalne zamrożenie wag\n",
    "weights_dict = dict(model.named_parameters())\n",
    "for k, v in weights_dict.items():\n",
    "    if \"box_predictor\" not in k:\n",
    "        v.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T21:34:49.774200400Z",
     "start_time": "2023-06-07T21:34:49.748177Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('labelj.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T21:35:02.652904900Z",
     "start_time": "2023-06-07T21:34:50.965283600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f56e415c49c4acea3c3b0fe33e81afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7060, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.8495,  152.1838,  483.4316, 1010.5036]], device='cuda:0')\n",
      "tensor(0.7044, device='cuda:0', grad_fn=<AddBackward0>) tensor([[224.9832, 224.9093, 557.9157, 915.3127]], device='cuda:0')\n",
      "tensor(0.7119, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.7688,  139.2857,  558.0228, 1129.5232]], device='cuda:0')\n",
      "tensor(0.7048, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 74.2857, 109.2857, 594.2857, 996.4286]], device='cuda:0')\n",
      "tensor(0.7039, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 109.0909,  249.5455,  535.0649, 1135.9091]], device='cuda:0')\n",
      "tensor(0.7179, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  38.5714,  135.0000,  512.8571, 1127.1428]], device='cuda:0')\n",
      "tensor(0.7043, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.4286,  175.7143,  484.2857, 1035.0000]], device='cuda:0')\n",
      "Val loss: 0.7107003927230835\n",
      "Val loss: 0.7131628394126892\n",
      "Val loss: 0.7021306753158569\n",
      "Val loss: 0.7113913297653198\n",
      "Val loss: 0.7094793319702148\n",
      "Val loss: 0.7017999291419983\n",
      "Val loss: 0.7043132781982422\n",
      "tensor(0.7007, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.8495,  152.1838,  483.4316, 1010.5036]], device='cuda:0')\n",
      "tensor(0.7163, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  63.4227,   93.4387,  516.0905, 1045.5739]], device='cuda:0')\n",
      "tensor(0.7054, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.4286,  175.7143,  484.2857, 1035.0000]], device='cuda:0')\n",
      "tensor(0.7046, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 109.0909,  249.5455,  535.0649, 1135.9091]], device='cuda:0')\n",
      "tensor(0.7024, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  38.5714,  135.0000,  512.8571, 1127.1428]], device='cuda:0')\n",
      "tensor(0.7193, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  55.7143,  139.2857,  587.1429, 1105.7142]], device='cuda:0')\n",
      "tensor(0.7051, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 74.2857, 109.2857, 594.2857, 996.4286]], device='cuda:0')\n",
      "Val loss: 0.7168600559234619\n",
      "Val loss: 0.7007534503936768\n",
      "Val loss: 0.7094076871871948\n",
      "Val loss: 0.701968789100647\n",
      "Val loss: 0.6967224478721619\n",
      "Val loss: 0.7161905765533447\n",
      "Val loss: 0.7123234868049622\n",
      "tensor(0.7123, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  52.4154,   80.9342,  537.8630, 1115.2775]], device='cuda:0')\n",
      "tensor(0.7013, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  49.3721,  103.1338,  553.8264, 1132.7262]], device='cuda:0')\n",
      "tensor(0.7088, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  63.4227,   93.4387,  516.0905, 1045.5739]], device='cuda:0')\n",
      "tensor(0.7018, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.8495,  152.1838,  483.4316, 1010.5036]], device='cuda:0')\n",
      "tensor(0.7068, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  78.5714,  152.1429,  531.4286, 1082.1428]], device='cuda:0')\n",
      "tensor(0.7005, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 74.2857, 109.2857, 594.2857, 996.4286]], device='cuda:0')\n",
      "tensor(0.7200, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  55.7143,  139.2857,  587.1429, 1105.7142]], device='cuda:0')\n",
      "Val loss: 0.7027201056480408\n",
      "Val loss: 0.7106878161430359\n",
      "Val loss: 0.7039481997489929\n",
      "Val loss: 0.7151923775672913\n",
      "Val loss: 0.700695812702179\n",
      "Val loss: 0.7026776671409607\n",
      "Val loss: 0.718161404132843\n",
      "tensor(0.7080, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  38.5714,  135.0000,  512.8571, 1127.1428]], device='cuda:0')\n",
      "tensor(0.6957, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.8495,  152.1838,  483.4316, 1010.5036]], device='cuda:0')\n",
      "tensor(0.7088, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 74.2857, 109.2857, 594.2857, 996.4286]], device='cuda:0')\n",
      "tensor(0.7043, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  95.7143,  152.1429,  567.1429, 1133.5714]], device='cuda:0')\n",
      "tensor(0.7184, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  55.7143,  139.2857,  587.1429, 1105.7142]], device='cuda:0')\n",
      "tensor(0.7072, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  52.4154,   80.9342,  537.8630, 1115.2775]], device='cuda:0')\n",
      "tensor(0.7123, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.7688,  139.2857,  558.0228, 1129.5232]], device='cuda:0')\n",
      "Val loss: 0.7043430209159851\n",
      "Val loss: 0.7205298542976379\n",
      "Val loss: 0.6971530318260193\n",
      "Val loss: 0.7077709436416626\n",
      "Val loss: 0.7091748714447021\n",
      "Val loss: 0.7005985975265503\n",
      "Val loss: 0.7147967219352722\n",
      "tensor(0.7073, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  78.5714,  152.1429,  531.4286, 1082.1428]], device='cuda:0')\n",
      "tensor(0.7095, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 109.0909,  249.5455,  535.0649, 1135.9091]], device='cuda:0')\n",
      "tensor(0.7015, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 74.2857, 109.2857, 594.2857, 996.4286]], device='cuda:0')\n",
      "tensor(0.7166, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.7688,  139.2857,  558.0228, 1129.5232]], device='cuda:0')\n",
      "tensor(0.7134, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  95.7143,  152.1429,  567.1429, 1133.5714]], device='cuda:0')\n",
      "tensor(0.7037, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.4286,  175.7143,  484.2857, 1035.0000]], device='cuda:0')\n",
      "tensor(0.7026, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  57.1429,   94.2857,  550.0000, 1131.4286]], device='cuda:0')\n",
      "Val loss: 0.7118409872055054\n",
      "Val loss: 0.7046713829040527\n",
      "Val loss: 0.7114260792732239\n",
      "Val loss: 0.700167715549469\n",
      "Val loss: 0.7044684290885925\n",
      "Val loss: 0.7177673578262329\n",
      "Val loss: 0.7007406949996948\n",
      "tensor(0.6999, device='cuda:0', grad_fn=<AddBackward0>) tensor([[224.9832, 224.9093, 557.9157, 915.3127]], device='cuda:0')\n",
      "tensor(0.7132, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  49.3721,  103.1338,  553.8264, 1132.7262]], device='cuda:0')\n",
      "tensor(0.7026, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.7688,  139.2857,  558.0228, 1129.5232]], device='cuda:0')\n",
      "tensor(0.7058, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  57.1429,   94.2857,  550.0000, 1131.4286]], device='cuda:0')\n",
      "tensor(0.7045, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  95.7143,  152.1429,  567.1429, 1133.5714]], device='cuda:0')\n",
      "tensor(0.7078, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  38.5714,  135.0000,  512.8571, 1127.1428]], device='cuda:0')\n",
      "tensor(0.7189, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  55.7143,  139.2857,  587.1429, 1105.7142]], device='cuda:0')\n",
      "Val loss: 0.7020888924598694\n",
      "Val loss: 0.7125698328018188\n",
      "Val loss: 0.7071641087532043\n",
      "Val loss: 0.7134639024734497\n",
      "Val loss: 0.7072980403900146\n",
      "Val loss: 0.7009590268135071\n",
      "Val loss: 0.7075147032737732\n",
      "tensor(0.7182, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  55.7143,  139.2857,  587.1429, 1105.7142]], device='cuda:0')\n",
      "tensor(0.7038, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 109.0909,  249.5455,  535.0649, 1135.9091]], device='cuda:0')\n",
      "tensor(0.7059, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  63.4227,   93.4387,  516.0905, 1045.5739]], device='cuda:0')\n",
      "tensor(0.7055, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.8495,  152.1838,  483.4316, 1010.5036]], device='cuda:0')\n",
      "tensor(0.7098, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  78.5714,  152.1429,  531.4286, 1082.1428]], device='cuda:0')\n",
      "tensor(0.7121, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  52.4154,   80.9342,  537.8630, 1115.2775]], device='cuda:0')\n",
      "tensor(0.7010, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.4286,  175.7143,  484.2857, 1035.0000]], device='cuda:0')\n",
      "Val loss: 0.7200868725776672\n",
      "Val loss: 0.7077406048774719\n",
      "Val loss: 0.6949290633201599\n",
      "Val loss: 0.7162092924118042\n",
      "Val loss: 0.7032268047332764\n",
      "Val loss: 0.7110546827316284\n",
      "Val loss: 0.7003412842750549\n",
      "tensor(0.7104, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  49.3721,  103.1338,  553.8264, 1132.7262]], device='cuda:0')\n",
      "tensor(0.7107, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.8495,  152.1838,  483.4316, 1010.5036]], device='cuda:0')\n",
      "tensor(0.7040, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  57.1429,   94.2857,  550.0000, 1131.4286]], device='cuda:0')\n",
      "tensor(0.7108, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  78.5714,  152.1429,  531.4286, 1082.1428]], device='cuda:0')\n",
      "tensor(0.7050, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  52.4154,   80.9342,  537.8630, 1115.2775]], device='cuda:0')\n",
      "tensor(0.7063, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.7688,  139.2857,  558.0228, 1129.5232]], device='cuda:0')\n",
      "tensor(0.7041, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.4286,  175.7143,  484.2857, 1035.0000]], device='cuda:0')\n",
      "Val loss: 0.7083994746208191\n",
      "Val loss: 0.7128003835678101\n",
      "Val loss: 0.7058038115501404\n",
      "Val loss: 0.7184205055236816\n",
      "Val loss: 0.7020915150642395\n",
      "Val loss: 0.7094302177429199\n",
      "Val loss: 0.6995404958724976\n",
      "tensor(0.7019, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.4286,  175.7143,  484.2857, 1035.0000]], device='cuda:0')\n",
      "tensor(0.7133, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  95.7143,  152.1429,  567.1429, 1133.5714]], device='cuda:0')\n",
      "tensor(0.7016, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.7688,  139.2857,  558.0228, 1129.5232]], device='cuda:0')\n",
      "tensor(0.7140, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  57.1429,   94.2857,  550.0000, 1131.4286]], device='cuda:0')\n",
      "tensor(0.7091, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  55.7143,  139.2857,  587.1429, 1105.7142]], device='cuda:0')\n",
      "tensor(0.7117, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 74.2857, 109.2857, 594.2857, 996.4286]], device='cuda:0')\n",
      "tensor(0.7013, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.8495,  152.1838,  483.4316, 1010.5036]], device='cuda:0')\n",
      "Val loss: 0.7096313238143921\n",
      "Val loss: 0.7050350904464722\n",
      "Val loss: 0.704761803150177\n",
      "Val loss: 0.7017638683319092\n",
      "Val loss: 0.7016708850860596\n",
      "Val loss: 0.7150900363922119\n",
      "Val loss: 0.717329204082489\n",
      "tensor(0.7103, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  63.4227,   93.4387,  516.0905, 1045.5739]], device='cuda:0')\n",
      "tensor(0.7141, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  95.7143,  152.1429,  567.1429, 1133.5714]], device='cuda:0')\n",
      "tensor(0.7025, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.4286,  175.7143,  484.2857, 1035.0000]], device='cuda:0')\n",
      "tensor(0.7110, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  52.4154,   80.9342,  537.8630, 1115.2775]], device='cuda:0')\n",
      "tensor(0.7012, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 74.2857, 109.2857, 594.2857, 996.4286]], device='cuda:0')\n",
      "tensor(0.7099, device='cuda:0', grad_fn=<AddBackward0>) tensor([[224.9832, 224.9093, 557.9157, 915.3127]], device='cuda:0')\n",
      "tensor(0.7033, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  49.3721,  103.1338,  553.8264, 1132.7262]], device='cuda:0')\n",
      "Val loss: 0.7048031687736511\n",
      "Val loss: 0.7004354000091553\n",
      "Val loss: 0.714617133140564\n",
      "Val loss: 0.7055146098136902\n",
      "Val loss: 0.7025048732757568\n",
      "Val loss: 0.7199059128761292\n",
      "Val loss: 0.7075194120407104\n",
      "tensor(0.7060, device='cuda:0', grad_fn=<AddBackward0>) tensor([[224.9832, 224.9093, 557.9157, 915.3127]], device='cuda:0')\n",
      "tensor(0.7097, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.8495,  152.1838,  483.4316, 1010.5036]], device='cuda:0')\n",
      "tensor(0.7088, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.7688,  139.2857,  558.0228, 1129.5232]], device='cuda:0')\n",
      "tensor(0.7031, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  78.5714,  152.1429,  531.4286, 1082.1428]], device='cuda:0')\n",
      "tensor(0.7103, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  49.3721,  103.1338,  553.8264, 1132.7262]], device='cuda:0')\n",
      "tensor(0.7015, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.4286,  175.7143,  484.2857, 1035.0000]], device='cuda:0')\n",
      "tensor(0.7131, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  38.5714,  135.0000,  512.8571, 1127.1428]], device='cuda:0')\n",
      "Val loss: 0.6989072561264038\n",
      "Val loss: 0.7072304487228394\n",
      "Val loss: 0.7041526436805725\n",
      "Val loss: 0.7095685601234436\n",
      "Val loss: 0.702903687953949\n",
      "Val loss: 0.7082535028457642\n",
      "Val loss: 0.7196522951126099\n",
      "tensor(0.7176, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  49.3721,  103.1338,  553.8264, 1132.7262]], device='cuda:0')\n",
      "tensor(0.7049, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 74.2857, 109.2857, 594.2857, 996.4286]], device='cuda:0')\n",
      "tensor(0.6946, device='cuda:0', grad_fn=<AddBackward0>) tensor([[224.9832, 224.9093, 557.9157, 915.3127]], device='cuda:0')\n",
      "tensor(0.7166, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  63.4227,   93.4387,  516.0905, 1045.5739]], device='cuda:0')\n",
      "tensor(0.6953, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.8495,  152.1838,  483.4316, 1010.5036]], device='cuda:0')\n",
      "tensor(0.7095, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  78.5714,  152.1429,  531.4286, 1082.1428]], device='cuda:0')\n",
      "tensor(0.7126, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  57.1429,   94.2857,  550.0000, 1131.4286]], device='cuda:0')\n",
      "Val loss: 0.7088758945465088\n",
      "Val loss: 0.7019973993301392\n",
      "Val loss: 0.7104266285896301\n",
      "Val loss: 0.7196556329727173\n",
      "Val loss: 0.7070590257644653\n",
      "Val loss: 0.6953467130661011\n",
      "Val loss: 0.708859384059906\n",
      "tensor(0.7126, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  38.5714,  135.0000,  512.8571, 1127.1428]], device='cuda:0')\n",
      "tensor(0.7004, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.4286,  175.7143,  484.2857, 1035.0000]], device='cuda:0')\n",
      "tensor(0.7121, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  49.3721,  103.1338,  553.8264, 1132.7262]], device='cuda:0')\n",
      "tensor(0.7164, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  55.7143,  139.2857,  587.1429, 1105.7142]], device='cuda:0')\n",
      "tensor(0.7165, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  63.4227,   93.4387,  516.0905, 1045.5739]], device='cuda:0')\n",
      "tensor(0.7011, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  78.5714,  152.1429,  531.4286, 1082.1428]], device='cuda:0')\n",
      "tensor(0.6955, device='cuda:0', grad_fn=<AddBackward0>) tensor([[224.9832, 224.9093, 557.9157, 915.3127]], device='cuda:0')\n",
      "Val loss: 0.7097578048706055\n",
      "Val loss: 0.6956473588943481\n",
      "Val loss: 0.7193437218666077\n",
      "Val loss: 0.704948365688324\n",
      "Val loss: 0.7076753973960876\n",
      "Val loss: 0.7060793042182922\n",
      "Val loss: 0.7080833911895752\n",
      "tensor(0.6955, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 109.0909,  249.5455,  535.0649, 1135.9091]], device='cuda:0')\n",
      "tensor(0.7088, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.7688,  139.2857,  558.0228, 1129.5232]], device='cuda:0')\n",
      "tensor(0.7160, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  95.7143,  152.1429,  567.1429, 1133.5714]], device='cuda:0')\n",
      "tensor(0.7042, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.4286,  175.7143,  484.2857, 1035.0000]], device='cuda:0')\n",
      "tensor(0.7209, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  57.1429,   94.2857,  550.0000, 1131.4286]], device='cuda:0')\n",
      "tensor(0.7000, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.8495,  152.1838,  483.4316, 1010.5036]], device='cuda:0')\n",
      "tensor(0.7100, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  52.4154,   80.9342,  537.8630, 1115.2775]], device='cuda:0')\n",
      "Val loss: 0.7078957557678223\n",
      "Val loss: 0.6981524229049683\n",
      "Val loss: 0.6946220397949219\n",
      "Val loss: 0.7196483612060547\n",
      "Val loss: 0.707214891910553\n",
      "Val loss: 0.7100359201431274\n",
      "Val loss: 0.7156886458396912\n",
      "tensor(0.7081, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  95.7143,  152.1429,  567.1429, 1133.5714]], device='cuda:0')\n",
      "tensor(0.7050, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 109.0909,  249.5455,  535.0649, 1135.9091]], device='cuda:0')\n",
      "tensor(0.7117, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  63.4227,   93.4387,  516.0905, 1045.5739]], device='cuda:0')\n",
      "tensor(0.6984, device='cuda:0', grad_fn=<AddBackward0>) tensor([[224.9832, 224.9093, 557.9157, 915.3127]], device='cuda:0')\n",
      "tensor(0.7056, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  52.4154,   80.9342,  537.8630, 1115.2775]], device='cuda:0')\n",
      "tensor(0.7181, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  38.5714,  135.0000,  512.8571, 1127.1428]], device='cuda:0')\n",
      "tensor(0.7036, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.8495,  152.1838,  483.4316, 1010.5036]], device='cuda:0')\n",
      "Val loss: 0.7046257853507996\n",
      "Val loss: 0.7152985334396362\n",
      "Val loss: 0.7101668119430542\n",
      "Val loss: 0.7065396308898926\n",
      "Val loss: 0.7121837139129639\n",
      "Val loss: 0.6981704235076904\n",
      "Val loss: 0.6990022659301758\n",
      "tensor(0.7188, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  49.3721,  103.1338,  553.8264, 1132.7262]], device='cuda:0')\n",
      "tensor(0.7083, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 109.0909,  249.5455,  535.0649, 1135.9091]], device='cuda:0')\n",
      "tensor(0.7011, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.8495,  152.1838,  483.4316, 1010.5036]], device='cuda:0')\n",
      "tensor(0.7048, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.4286,  175.7143,  484.2857, 1035.0000]], device='cuda:0')\n",
      "tensor(0.7085, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 74.2857, 109.2857, 594.2857, 996.4286]], device='cuda:0')\n",
      "tensor(0.7003, device='cuda:0', grad_fn=<AddBackward0>) tensor([[224.9832, 224.9093, 557.9157, 915.3127]], device='cuda:0')\n",
      "tensor(0.7115, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  57.1429,   94.2857,  550.0000, 1131.4286]], device='cuda:0')\n",
      "Val loss: 0.696694016456604\n",
      "Val loss: 0.7084826231002808\n",
      "Val loss: 0.7195625901222229\n",
      "Val loss: 0.7098134756088257\n",
      "Val loss: 0.7048760056495667\n",
      "Val loss: 0.6991975903511047\n",
      "Val loss: 0.7155159711837769\n",
      "tensor(0.7071, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 74.2857, 109.2857, 594.2857, 996.4286]], device='cuda:0')\n",
      "tensor(0.7108, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  55.7143,  139.2857,  587.1429, 1105.7142]], device='cuda:0')\n",
      "tensor(0.7162, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  63.4227,   93.4387,  516.0905, 1045.5739]], device='cuda:0')\n",
      "tensor(0.7140, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  57.1429,   94.2857,  550.0000, 1131.4286]], device='cuda:0')\n",
      "tensor(0.7075, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  78.5714,  152.1429,  531.4286, 1082.1428]], device='cuda:0')\n",
      "tensor(0.6960, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 109.0909,  249.5455,  535.0649, 1135.9091]], device='cuda:0')\n",
      "tensor(0.7038, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.4286,  175.7143,  484.2857, 1035.0000]], device='cuda:0')\n",
      "Val loss: 0.7000805735588074\n",
      "Val loss: 0.707631528377533\n",
      "Val loss: 0.6941701769828796\n",
      "Val loss: 0.7110117673873901\n",
      "Val loss: 0.7179479598999023\n",
      "Val loss: 0.7134367227554321\n",
      "Val loss: 0.7083006501197815\n",
      "tensor(0.7095, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  78.5714,  152.1429,  531.4286, 1082.1428]], device='cuda:0')\n",
      "tensor(0.7154, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 74.2857, 109.2857, 594.2857, 996.4286]], device='cuda:0')\n",
      "tensor(0.7122, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  57.1429,   94.2857,  550.0000, 1131.4286]], device='cuda:0')\n",
      "tensor(0.7160, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  95.7143,  152.1429,  567.1429, 1133.5714]], device='cuda:0')\n",
      "tensor(0.7011, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 109.0909,  249.5455,  535.0649, 1135.9091]], device='cuda:0')\n",
      "tensor(0.6939, device='cuda:0', grad_fn=<AddBackward0>) tensor([[224.9832, 224.9093, 557.9157, 915.3127]], device='cuda:0')\n",
      "tensor(0.7019, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  49.3721,  103.1338,  553.8264, 1132.7262]], device='cuda:0')\n",
      "Val loss: 0.708266019821167\n",
      "Val loss: 0.7019392251968384\n",
      "Val loss: 0.7040550708770752\n",
      "Val loss: 0.709449052810669\n",
      "Val loss: 0.7072420120239258\n",
      "Val loss: 0.7118565440177917\n",
      "Val loss: 0.7060544490814209\n",
      "tensor(0.6935, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.8495,  152.1838,  483.4316, 1010.5036]], device='cuda:0')\n",
      "tensor(0.6997, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.4286,  175.7143,  484.2857, 1035.0000]], device='cuda:0')\n",
      "tensor(0.7127, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  57.1429,   94.2857,  550.0000, 1131.4286]], device='cuda:0')\n",
      "tensor(0.7166, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  52.4154,   80.9342,  537.8630, 1115.2775]], device='cuda:0')\n",
      "tensor(0.7163, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  55.7143,  139.2857,  587.1429, 1105.7142]], device='cuda:0')\n",
      "tensor(0.7066, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  78.5714,  152.1429,  531.4286, 1082.1428]], device='cuda:0')\n",
      "tensor(0.7052, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 109.0909,  249.5455,  535.0649, 1135.9091]], device='cuda:0')\n",
      "Val loss: 0.7016293406486511\n",
      "Val loss: 0.7109385132789612\n",
      "Val loss: 0.7012660503387451\n",
      "Val loss: 0.7088136076927185\n",
      "Val loss: 0.7087860703468323\n",
      "Val loss: 0.7085450887680054\n",
      "Val loss: 0.7130902409553528\n",
      "tensor(0.7127, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  38.5714,  135.0000,  512.8571, 1127.1428]], device='cuda:0')\n",
      "tensor(0.7102, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.7688,  139.2857,  558.0228, 1129.5232]], device='cuda:0')\n",
      "tensor(0.7163, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  55.7143,  139.2857,  587.1429, 1105.7142]], device='cuda:0')\n",
      "tensor(0.6948, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 109.0909,  249.5455,  535.0649, 1135.9091]], device='cuda:0')\n",
      "tensor(0.7066, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  71.4286,  175.7143,  484.2857, 1035.0000]], device='cuda:0')\n",
      "tensor(0.7035, device='cuda:0', grad_fn=<AddBackward0>) tensor([[  57.1429,   94.2857,  550.0000, 1131.4286]], device='cuda:0')\n",
      "tensor(0.7059, device='cuda:0', grad_fn=<AddBackward0>) tensor([[ 74.2857, 109.2857, 594.2857, 996.4286]], device='cuda:0')\n",
      "Val loss: 0.6961551308631897\n",
      "Val loss: 0.7042519450187683\n",
      "Val loss: 0.7035766839981079\n",
      "Val loss: 0.7086984515190125\n",
      "Val loss: 0.7200945615768433\n",
      "Val loss: 0.7137582898139954\n",
      "Val loss: 0.7088383436203003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Hiperparametr\n",
    "epochs = 20\n",
    "#lr, momentum - hiperparametry\n",
    "#można spróbować torch.optim.Adam\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "training_dataset = TrainingDataset(data)\n",
    "#batch_size = 2 - hiperparametr\n",
    "training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=2, shuffle=True)\n",
    "val_dataset = TrainingDataset(data, validation=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "for epoch in tqdm(list(range(epochs))):\n",
    "    for images, boxes, labels in training_dataloader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = []\n",
    "        for i in range(len(images)):\n",
    "            d = {}\n",
    "            d['boxes'] = boxes[i].to(device)\n",
    "            d['labels'] = labels[i].to(device)\n",
    "            targets.append(d)\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(losses, d['boxes'])\n",
    "    with torch.no_grad():\n",
    "        for images, boxes, labels in val_dataloader:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = []\n",
    "            for i in range(len(images)):\n",
    "                d = {}\n",
    "                d['boxes'] = boxes[i].to(device)\n",
    "                d['labels'] = labels[i].to(device)\n",
    "                targets.append(d)\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            print(f\"Val loss: {losses.item()}\")\n",
    "\n",
    "#Zapisanie modelu\n",
    "torch.save(model.state_dict(), \"model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 29\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39m# if boxes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m#     boxes = torch.stack(boxes)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m#     box_im = draw_bounding_boxes(box_im, boxes=boxes,\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[39m#                           colors=\"green\",\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m#                           width=4)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m im \u001b[39m=\u001b[39m to_pil_image(box_im\u001b[39m.\u001b[39mdetach())\n\u001b[1;32m---> 29\u001b[0m im\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:2486\u001b[0m, in \u001b[0;36mImage.show\u001b[1;34m(self, title)\u001b[0m\n\u001b[0;32m   2466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow\u001b[39m(\u001b[39mself\u001b[39m, title\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2467\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2468\u001b[0m \u001b[39m    Displays this image. This method is mainly intended for debugging purposes.\u001b[39;00m\n\u001b[0;32m   2469\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2483\u001b[0m \u001b[39m    :param title: Optional title to use for the image window, where possible.\u001b[39;00m\n\u001b[0;32m   2484\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2486\u001b[0m     _show(\u001b[39mself\u001b[39;49m, title\u001b[39m=\u001b[39;49mtitle)\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:3524\u001b[0m, in \u001b[0;36m_show\u001b[1;34m(image, **options)\u001b[0m\n\u001b[0;32m   3521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_show\u001b[39m(image, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions):\n\u001b[0;32m   3522\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageShow\n\u001b[1;32m-> 3524\u001b[0m     ImageShow\u001b[39m.\u001b[39;49mshow(image, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageShow.py:62\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(image, title, **options)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[39mDisplay a given image.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m:returns: ``True`` if a suitable viewer was found, ``False`` otherwise.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39mfor\u001b[39;00m viewer \u001b[39min\u001b[39;00m _viewers:\n\u001b[1;32m---> 62\u001b[0m     \u001b[39mif\u001b[39;00m viewer\u001b[39m.\u001b[39;49mshow(image, title\u001b[39m=\u001b[39;49mtitle, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions):\n\u001b[0;32m     63\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageShow.py:86\u001b[0m, in \u001b[0;36mViewer.show\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m image\u001b[39m.\u001b[39mmode \u001b[39m!=\u001b[39m base:\n\u001b[0;32m     84\u001b[0m         image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mconvert(base)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshow_image(image, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageShow.py:112\u001b[0m, in \u001b[0;36mViewer.show_image\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow_image\u001b[39m(\u001b[39mself\u001b[39m, image, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions):\n\u001b[0;32m    111\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Display the given image.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshow_file(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_image(image), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageShow.py:129\u001b[0m, in \u001b[0;36mViewer.show_file\u001b[1;34m(self, path, **options)\u001b[0m\n\u001b[0;32m    127\u001b[0m         msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 129\u001b[0m os\u001b[39m.\u001b[39msystem(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_command(path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions))  \u001b[39m# nosec\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "import torch\n",
    "\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "for img, boxes, labels in val_dataset:\n",
    "    preds = model([img])\n",
    "    img = img*255\n",
    "    img = img.type(torch.uint8)\n",
    "    box_im = draw_bounding_boxes(img, boxes=boxes,\n",
    "\n",
    "                              colors=\"red\",\n",
    "                              width=4)\n",
    "    # boxes = [box for box, label, score in el.items() if label == 84 for el in preds]\n",
    "    boxes = []\n",
    "    for el in preds:\n",
    "        for box, label, score in zip(el['boxes'], el['labels'], el['scores']):\n",
    "            if label == 84:\n",
    "                boxes.append(box)\n",
    "    # if boxes:\n",
    "    #     boxes = torch.stack(boxes)\n",
    "    #     box_im = draw_bounding_boxes(box_im, boxes=boxes,\n",
    "\n",
    "    #                           colors=\"green\",\n",
    "    #                           width=4)\n",
    "    im = to_pil_image(box_im.detach())\n",
    "    im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 45\u001b[0m\n\u001b[0;32m     40\u001b[0m     box_im \u001b[39m=\u001b[39m draw_bounding_boxes(box_im, boxes\u001b[39m=\u001b[39mboxes,\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m                           colors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m                           width\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m     44\u001b[0m im \u001b[39m=\u001b[39m to_pil_image(box_im\u001b[39m.\u001b[39mdetach())\n\u001b[1;32m---> 45\u001b[0m im\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:2486\u001b[0m, in \u001b[0;36mImage.show\u001b[1;34m(self, title)\u001b[0m\n\u001b[0;32m   2466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow\u001b[39m(\u001b[39mself\u001b[39m, title\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2467\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2468\u001b[0m \u001b[39m    Displays this image. This method is mainly intended for debugging purposes.\u001b[39;00m\n\u001b[0;32m   2469\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2483\u001b[0m \u001b[39m    :param title: Optional title to use for the image window, where possible.\u001b[39;00m\n\u001b[0;32m   2484\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2486\u001b[0m     _show(\u001b[39mself\u001b[39;49m, title\u001b[39m=\u001b[39;49mtitle)\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:3524\u001b[0m, in \u001b[0;36m_show\u001b[1;34m(image, **options)\u001b[0m\n\u001b[0;32m   3521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_show\u001b[39m(image, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions):\n\u001b[0;32m   3522\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageShow\n\u001b[1;32m-> 3524\u001b[0m     ImageShow\u001b[39m.\u001b[39;49mshow(image, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageShow.py:62\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(image, title, **options)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[39mDisplay a given image.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m:returns: ``True`` if a suitable viewer was found, ``False`` otherwise.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39mfor\u001b[39;00m viewer \u001b[39min\u001b[39;00m _viewers:\n\u001b[1;32m---> 62\u001b[0m     \u001b[39mif\u001b[39;00m viewer\u001b[39m.\u001b[39;49mshow(image, title\u001b[39m=\u001b[39;49mtitle, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions):\n\u001b[0;32m     63\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageShow.py:86\u001b[0m, in \u001b[0;36mViewer.show\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m image\u001b[39m.\u001b[39mmode \u001b[39m!=\u001b[39m base:\n\u001b[0;32m     84\u001b[0m         image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mconvert(base)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshow_image(image, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageShow.py:112\u001b[0m, in \u001b[0;36mViewer.show_image\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow_image\u001b[39m(\u001b[39mself\u001b[39m, image, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions):\n\u001b[0;32m    111\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Display the given image.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshow_file(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_image(image), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageShow.py:129\u001b[0m, in \u001b[0;36mViewer.show_file\u001b[1;34m(self, path, **options)\u001b[0m\n\u001b[0;32m    127\u001b[0m         msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 129\u001b[0m os\u001b[39m.\u001b[39msystem(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_command(path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions))  \u001b[39m# nosec\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from torchvision.utils import draw_bounding_boxes\n",
    "# from torchvision.transforms.functional import to_pil_image\n",
    "# model = fasterrcnn_resnet50_fpn_v2(weights=FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT, box_score_thresh=0.5)\n",
    "# model.to(\"cpu\")\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "# from PIL import Image\n",
    "# from torchvision.transforms import ToTensor\n",
    "\n",
    "# # Ścieżka do testowego zdjęcia spoza bazy danych\n",
    "# image_path = r'C:\\Users\\Boows\\Desktop\\sieci\\test1.jpg'\n",
    "\n",
    "# # Wczytanie obrazu jako obiekt PIL.Image\n",
    "# image = Image.open(image_path)\n",
    "\n",
    "# # Przekształcenie obrazu na tensor\n",
    "# tensor_image = ToTensor()(image)\n",
    "\n",
    "# # Wykonanie predykcji na modelu\n",
    "# #preds = model([tensor_image])\n",
    "\n",
    "\n",
    "# for img, boxes, labels in val_dataset:\n",
    "#     preds = model([img])\n",
    "#     img = img*255\n",
    "#     img = img.type(torch.uint8)\n",
    "#     box_im = draw_bounding_boxes(img, boxes=boxes,\n",
    "\n",
    "#                               colors=\"red\",\n",
    "#                               width=4)\n",
    "#     # boxes = [box for box, label, score in el.items() if label == 84 for el in preds]\n",
    "#     boxes = []\n",
    "#     for el in preds:\n",
    "#         for box, label, score in zip(el['boxes'], el['labels'], el['scores']):\n",
    "#             if label == 84:\n",
    "#                 boxes.append(box)\n",
    "#     if boxes:\n",
    "#         boxes = torch.stack(boxes)\n",
    "#         box_im = draw_bounding_boxes(box_im, boxes=boxes,\n",
    "\n",
    "#                               colors=\"green\",\n",
    "#                               width=4)\n",
    "#     im = to_pil_image(box_im.detach())\n",
    "#     im.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m box_im \u001b[39m=\u001b[39m draw_bounding_boxes(img, boxes\u001b[39m=\u001b[39mboxes,\n\u001b[0;32m     39\u001b[0m                              colors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     40\u001b[0m                              width\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m     41\u001b[0m im \u001b[39m=\u001b[39m to_pil_image(box_im\u001b[39m.\u001b[39mdetach())\n\u001b[1;32m---> 42\u001b[0m im\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:2486\u001b[0m, in \u001b[0;36mImage.show\u001b[1;34m(self, title)\u001b[0m\n\u001b[0;32m   2466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow\u001b[39m(\u001b[39mself\u001b[39m, title\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2467\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2468\u001b[0m \u001b[39m    Displays this image. This method is mainly intended for debugging purposes.\u001b[39;00m\n\u001b[0;32m   2469\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2483\u001b[0m \u001b[39m    :param title: Optional title to use for the image window, where possible.\u001b[39;00m\n\u001b[0;32m   2484\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2486\u001b[0m     _show(\u001b[39mself\u001b[39;49m, title\u001b[39m=\u001b[39;49mtitle)\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:3524\u001b[0m, in \u001b[0;36m_show\u001b[1;34m(image, **options)\u001b[0m\n\u001b[0;32m   3521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_show\u001b[39m(image, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions):\n\u001b[0;32m   3522\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageShow\n\u001b[1;32m-> 3524\u001b[0m     ImageShow\u001b[39m.\u001b[39;49mshow(image, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageShow.py:62\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(image, title, **options)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[39mDisplay a given image.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m:returns: ``True`` if a suitable viewer was found, ``False`` otherwise.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39mfor\u001b[39;00m viewer \u001b[39min\u001b[39;00m _viewers:\n\u001b[1;32m---> 62\u001b[0m     \u001b[39mif\u001b[39;00m viewer\u001b[39m.\u001b[39;49mshow(image, title\u001b[39m=\u001b[39;49mtitle, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions):\n\u001b[0;32m     63\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageShow.py:86\u001b[0m, in \u001b[0;36mViewer.show\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m image\u001b[39m.\u001b[39mmode \u001b[39m!=\u001b[39m base:\n\u001b[0;32m     84\u001b[0m         image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mconvert(base)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshow_image(image, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageShow.py:112\u001b[0m, in \u001b[0;36mViewer.show_image\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow_image\u001b[39m(\u001b[39mself\u001b[39m, image, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions):\n\u001b[0;32m    111\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Display the given image.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshow_file(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_image(image), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\ImageShow.py:129\u001b[0m, in \u001b[0;36mViewer.show_file\u001b[1;34m(self, path, **options)\u001b[0m\n\u001b[0;32m    127\u001b[0m         msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 129\u001b[0m os\u001b[39m.\u001b[39msystem(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_command(path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions))  \u001b[39m# nosec\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#WYŚWIETLA WSZYSTKIE ZDJĘCIA\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "model = fasterrcnn_resnet50_fpn_v2(weights=FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT, box_score_thresh=0.7)\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Ścieżka do testowego zdjęcia spoza bazy danych\n",
    "image_path = r'C:\\Users\\Boows\\Desktop\\sieci\\test1.jpg'\n",
    "\n",
    "# Wczytanie obrazu jako obiekt PIL.Image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Przekształcenie obrazu na tensor\n",
    "tensor_image = ToTensor()(image)\n",
    "\n",
    "# Wykonanie predykcji na modelu\n",
    "#preds = model([tensor_image])\n",
    "\n",
    "\n",
    "for img, boxes, labels in val_dataset:\n",
    "    preds = model([img])\n",
    "    img = img * 255\n",
    "    img = img.type(torch.uint8)\n",
    "\n",
    "    # Rysowanie zielonych ramkach dla przewidywanych bounding boxów\n",
    "    boxes = []\n",
    "    for el in preds:\n",
    "        for box, label, score in zip(el['boxes'], el['labels'], el['scores']):\n",
    "            if label == 84:\n",
    "                boxes.append(box)\n",
    "    if boxes:\n",
    "        boxes = torch.stack(boxes)\n",
    "        box_im = draw_bounding_boxes(img, boxes=boxes,\n",
    "                                     colors=\"green\",\n",
    "                                     width=4)\n",
    "        im = to_pil_image(box_im.detach())\n",
    "        im.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WYŚWIETLA PODANE ZDJĘCIE ZE ŚCIEŻKI\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "model = fasterrcnn_resnet50_fpn_v2(weights=FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT, box_score_thresh=0.8)\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Ścieżka do testowego zdjęcia spoza bazy danych\n",
    "image_path = r'C:\\Users\\Boows\\Desktop\\sieci\\proba3.jpg'\n",
    "\n",
    "# Wczytanie obrazu jako obiekt PIL.Image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Przekształcenie obrazu na tensor\n",
    "tensor_image = ToTensor()(image)\n",
    "\n",
    "# Wykonanie predykcji na modelu\n",
    "preds = model([tensor_image])\n",
    "\n",
    "# Rysowanie zielonych ramkach dla przewidywanych bounding boxów\n",
    "img = tensor_image * 255\n",
    "img = img.type(torch.uint8)\n",
    "boxes = []\n",
    "for el in preds:\n",
    "    for box, label, score in zip(el['boxes'], el['labels'], el['scores']):\n",
    "        if label == 84:\n",
    "            boxes.append(box)\n",
    "if boxes:\n",
    "    boxes = torch.stack(boxes)\n",
    "    box_im = draw_bounding_boxes(img, boxes=boxes,\n",
    "                                 colors=\"green\",\n",
    "                                 width=4)\n",
    "    im = to_pil_image(box_im.detach())\n",
    "    im.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import torch\n",
    "\n",
    "model = fasterrcnn_resnet50_fpn_v2(pretrained=True)\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Ścieżka do testowego zdjęcia spoza bazy danych\n",
    "image_path = r'C:\\Users\\Boows\\Desktop\\sieci\\test1.jpg'\n",
    "\n",
    "# Wczytanie obrazu jako obiekt PIL.Image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Przekształcenie obrazu na tensor\n",
    "tensor_image = ToTensor()(image)\n",
    "\n",
    "# Wykonanie predykcji na modelu\n",
    "preds = model([tensor_image])\n",
    "\n",
    "# Wyciągnięcie pierwszego bounding boxa o etykiecie 84\n",
    "target_box = None\n",
    "for box, label in zip(preds[0]['boxes'], preds[0]['labels']):\n",
    "    if label == 84:\n",
    "        target_box = box\n",
    "        break\n",
    "\n",
    "# Jeżeli znaleziono bounding box o etykiecie 84, wycięcie wnętrza i wyświetlenie\n",
    "if target_box is not None:\n",
    "    xmin, ymin, xmax, ymax = target_box.tolist()\n",
    "    xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax)\n",
    "    cropped_img = image.crop((xmin, ymin, xmax, ymax))\n",
    "    cropped_img.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poprawnie zlutowany projekt\n",
      "\n",
      "Zasady dziatania oraz napotkane problemy:\n",
      "\n",
      "Dzlatanie powy2szego projektu nie jest skomplikowane. Po podtaczeniu\n",
      "zasilania zapal sie dioda LED ktora poinformuje nas o tym, iz zasilanie jest sprawne.\n",
      "Nastepnie wystarczy nacisnaé guzik aby otrzymac dawigk z brzgczyka. Wysokos¢\n",
      "wydawanego déwieku jest Zalezna z ulozeniem guzikow, im dalej w prawo tym\n",
      "Gawigk jest wy2szy, 2 Wiec skrajnie lewy guzik wydaje najnizszy dwigk a skrajnie\n",
      "prawy najwy2szy. Jednak mozna rowniez samemu ustawié wysokosé kazdego\n",
      "Géwigku poprzez zmiany wartosci na potencjometrze z jednoczesnym\n",
      "przytrzymaniem wybranego guzika.\n",
      "\n",
      "“Jedynym napotkanym problem, Ktéry mégl zawazyé na niewlaéciwym\n",
      "dziataniem projektu bylo, niepoprawne zaprojektowanie Sciezek do ukladu scalonego\n",
      "NESS, Jednak po szybkiej Konsultacji z prowadzacym, udalo sie doprowadzie\n",
      "projekt do jego poprawnego dzialania poprzez odgiecie jedne| z ndzek\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def read_text_from_image(image_path):\n",
    "    # Wczytanie obrazu\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Konwersja obrazu na tekst\n",
    "    text = pytesseract.image_to_string(image)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Ścieżka do pliku z obrazem\n",
    "image_path = r'C:\\Users\\Boows\\Desktop\\sieci\\test1.jpg'\n",
    "\n",
    "# Odczytanie tekstu z obrazu\n",
    "text = read_text_from_image(image_path)\n",
    "\n",
    "# Wyświetlenie odczytanego tekstu\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odczytany tekst został zapisany do pliku: output.txt\n"
     ]
    }
   ],
   "source": [
    "# import pytesseract\n",
    "# from PIL import Image\n",
    "\n",
    "\n",
    "# def read_text_from_image(cropped_img):\n",
    "#     # Konwersja obrazu na tekst\n",
    "#     text = pytesseract.image_to_string(cropped_img)\n",
    "\n",
    "#     return text\n",
    "\n",
    "# # Odczytanie tekstu z wyciętego zdjęcia\n",
    "# text = read_text_from_image(cropped_img)\n",
    "\n",
    "# # Wyświetlenie odczytanego tekstu\n",
    "# print(text)\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "def read_text_from_image(cropped_img):\n",
    "    # Konwersja obrazu na tekst\n",
    "    text = pytesseract.image_to_string(cropped_img)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Odczytanie tekstu z wyciętego zdjęcia\n",
    "text = read_text_from_image(cropped_img)\n",
    "\n",
    "# Ścieżka do pliku tekstowego, w którym chcemy zapisać odczytany tekst\n",
    "output_file = \"output.txt\"\n",
    "\n",
    "# Zapisanie odczytanego tekstu do pliku\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(text)\n",
    "\n",
    "print(\"Odczytany tekst został zapisany do pliku:\", output_file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
