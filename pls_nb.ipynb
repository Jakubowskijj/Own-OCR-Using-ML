{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T21:40:57.676160300Z",
     "start_time": "2023-06-07T21:40:57.668153Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import json\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T21:40:57.949409Z",
     "start_time": "2023-06-07T21:40:57.933394300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class TrainingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.images = []\n",
    "        self.boxes = []\n",
    "\n",
    "\n",
    "\n",
    "        x_final, y_final = 600, 1200\n",
    "        transform = Resize((x_final, y_final))\n",
    "        to_tensor = ToTensor()\n",
    "        for item in data:\n",
    "\n",
    "            file_name = item['data']['image'].split('-')[-1]\n",
    "\n",
    "            # r'C:\\Users\\Boows\\Desktop\\sieci\\\\' +\n",
    "            image_path = file_name  # Zmień odpowiednio ścieżkę do katalogu ze zdjęciami\n",
    "            image = Image.open(image_path)\n",
    "            image = transform(to_tensor(image))\n",
    "            self.images.append(image)\n",
    "\n",
    "            points = item['annotations'][0]['result'][0]['value']['points']\n",
    "\n",
    "            xmin = min(point[0] for point in points)/100*x_final\n",
    "            ymin = min(point[1] for point in points)/100*y_final\n",
    "            xmax = max(point[0] for point in points)/100*x_final\n",
    "            ymax = max(point[1] for point in points)/100*y_final\n",
    "            box = torch.tensor([[xmin, ymin, xmax, ymax]])\n",
    "            self.boxes.append(box)\n",
    "\n",
    "        self.labels = torch.zeros((len(data), 1), dtype=torch.int64)\n",
    "\n",
    "\n",
    "        self.transforms = T.Compose([\n",
    "        T.RandomApply(T.CenterCrop(10),p=0.5),\n",
    "        T.RandomApply(T.PILToTensor(),p=0.5),\n",
    "        T.RandomApply(T.ElasticTransform(alpha=45.0),p=0.5),\n",
    "        T.RandomApply(T.ConvertImageDtype(torch.float),p=0.5)])\n",
    "        self.transforms = None\n",
    "\n",
    "    # def crop_img_with_box(self, img, box):\n",
    "    #     # TODO: crop image with box\n",
    "    #     return img, box\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_img = self.images[idx]\n",
    "        if self.transforms is not None:\n",
    "            out_img = self.transforms(out_img)\n",
    "\n",
    "        out_box = self.boxes[idx]\n",
    "        # out_img, out_box = self.crop_img_with_box(out_img, out_box)\n",
    "\n",
    "        return out_img, out_box, self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T21:40:58.633030200Z",
     "start_time": "2023-06-07T21:40:58.282711400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn()\n",
    "model.roi_heads.box_predictor.cls_score = nn.Linear(1024, 1, bias=True)\n",
    "model.roi_heads.box_predictor.bbox_pred = nn.Linear(1024, 4, bias=True)\n",
    "\n",
    "#Opcjonalne zamrożenie wag\n",
    "weights_dict = dict(model.named_parameters())\n",
    "for k, v in weights_dict.items():\n",
    "    if \"box_predictor\" not in k:\n",
    "        v.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T21:40:58.650045400Z",
     "start_time": "2023-06-07T21:40:58.634030600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Wczytaj plik JSON\n",
    "with open('labelj.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T21:41:16.851587600Z",
     "start_time": "2023-06-07T21:40:58.940309500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m val_dataset \u001b[39m=\u001b[39m TrainingDataset(data)\n\u001b[0;32m     12\u001b[0m val_dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(training_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 14\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mlist\u001b[39;49m(\u001b[39mrange\u001b[39;49m(epochs))):\n\u001b[0;32m     15\u001b[0m     \u001b[39mfor\u001b[39;00m images, boxes, labels \u001b[39min\u001b[39;00m training_dataloader:\n\u001b[0;32m     16\u001b[0m         images \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(image\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m images)\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\notebook.py:238\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m unit_scale \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munit_scale \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munit_scale \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m    237\u001b[0m total \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39m*\u001b[39m unit_scale \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal\n\u001b[1;32m--> 238\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstatus_printer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp, total, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdesc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mncols)\n\u001b[0;32m    239\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer\u001b[39m.\u001b[39mpbar \u001b[39m=\u001b[39m proxy(\u001b[39mself\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisplayed \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Boows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\notebook.py:113\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[39m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[39m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m \n\u001b[0;32m    111\u001b[0m \u001b[39m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m IProgress \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    114\u001b[0m \u001b[39mif\u001b[39;00m total:\n\u001b[0;32m    115\u001b[0m     pbar \u001b[39m=\u001b[39m IProgress(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39mtotal)\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "#Hiperparametr\n",
    "epochs = 10\n",
    "#lr, momentum - hiperparametry\n",
    "#można spróbować torch.optim.Adam\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "training_dataset = TrainingDataset(data)\n",
    "#batch_size = 2 - hiperparametr\n",
    "training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=2, shuffle=True)\n",
    "val_dataset = TrainingDataset(data)\n",
    "val_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "for epoch in tqdm(list(range(epochs))):\n",
    "    for images, boxes, labels in training_dataloader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = []\n",
    "        for i in range(len(images)):\n",
    "            d = {}\n",
    "            d['boxes'] = boxes[i].to(device)\n",
    "            d['labels'] = labels[i].to(device)\n",
    "            targets.append(d)\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(losses)\n",
    "\n",
    "    for images, boxes, labels in val_dataloader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = []\n",
    "        for i in range(len(images)):\n",
    "            d = {}\n",
    "            d['boxes'] = boxes[i].to(device)\n",
    "            d['labels'] = labels[i].to(device)\n",
    "            targets.append(d)\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        print(f\"Val loss: {losses.item()}\")\n",
    "\n",
    "#Zapisanie modelu\n",
    "torch.save(model.state_dict(), \"model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
